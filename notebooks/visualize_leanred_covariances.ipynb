{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mpld3\n",
    "# mpld3.enable_notebook()\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "\n",
    "import torch, sys\n",
    "sys.path.append('..')\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data.base_dataset import BasicDatasetLT\n",
    "\n",
    "from src import options\n",
    "from src.models.fc_model import BaseModelLT\n",
    "\n",
    "from src.utils.complex_tensors import complextorch2numpy\n",
    "import src.utils.visualizations as vis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "# %matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/options/__init__.py:85: UserWarning: GPU is not available, using CPU instead\n",
      "  warnings.warn('GPU is not available, using CPU instead')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Parameters: \n",
      "experiment_name: fc_imagemethod_full\n",
      "model_name: fc\n",
      "rank: None\n",
      "hidden_layers: 2\n",
      "hidden_sizes: [3000, 3000]\n",
      "residual_flag: True\n",
      "residual_only: False\n",
      "loss: mse\n",
      "transform: None\n",
      "batch_size: 10\n",
      "num_workers: 8\n",
      "train_val_split: [0.9, 0.1]\n",
      "preload_data: True\n",
      "lr: 0.0001\n",
      "max_epochs: 100\n",
      "gpus: 0\n",
      "input_size: 512\n",
      "output_shape: torch.Size([2, 49, 49])\n",
      "last_layer_size: 4802\n",
      "data_path: /Users/ranweisman/PycharmProjects/nn-ambisonics-upscaler/notebooks/../data/raw/image-method\n",
      "logs_path: /Users/ranweisman/PycharmProjects/nn-ambisonics-upscaler/notebooks/../experiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelLT(\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=512, out_features=3000, bias=True)\n",
       "    (1): Linear(in_features=3000, out_features=3000, bias=True)\n",
       "    (2): Linear(in_features=3000, out_features=4802, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- load model ---\n",
    "\n",
    "# CKPT_PATH = '/Users/ranweisman/PycharmProjects/nn-ambisonics-upscaler/experiments/cloud_experiments/fc_hp_tune/fc_imagemethod_lowrank/version_467/checkpoints/epoch=99.ckpt'\n",
    "\n",
    "# files = glob.glob('/Users/ranweisman/PycharmProjects/nn-ambisonics-upscaler/experiments/cloud_experiments/fc_hp_tune/fc_imagemethod_full/*/checkpoints/*.ckpt')\n",
    "CKPT_PATH = '/Users/ranweisman/PycharmProjects/nn-ambisonics-upscaler/experiments/cloud_experiments/fc_hp_tune/fc_imagemethod_full/version_202/checkpoints/epoch=99.ckpt'\n",
    "# CKPT_PATH = files[221]\n",
    "\n",
    "\n",
    "checkpoint = torch.load(CKPT_PATH,map_location=torch.device('cpu'))\n",
    "opts = checkpoint['hyper_parameters']['opts'].copy()\n",
    "del opts['data_path'],opts['logs_path']\n",
    "\n",
    "base_opts = options.get_default_opts(opts)\n",
    "full_opts = options.prepare_opts(base_opts,opts)\n",
    "full_opts = options.validate_opts(full_opts)\n",
    "\n",
    "model = BaseModelLT(opts)\n",
    "model.setup('test')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "trainer = Trainer()\n",
    "model.eval()\n",
    "\n",
    "# # --- load data ---\n",
    "#  loader = DataLoader(model.dataset_train, batch_size=model.hparams.batch_size, num_workers=model.hparams.num_workers)\n",
    "#\n",
    "# # --- estimate performance over all dataset ---\n",
    "#  trainer.test(model,test_dataloaders=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b1c89e033d42b1b2cc2668d32d51b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c77f377f13146aebee1734c6cbf6ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.22660959+0.j         -0.09698426-0.02019086j -0.04476041+0.09965498j\n",
      "  0.06924256+0.01552413j  0.00867056-0.01190673j -0.00907483-0.10580169j\n",
      " -0.06110267+0.03819351j -0.06272898+0.05898398j  0.02554221-0.05228046j\n",
      "  0.17901121+0.07579478j  0.06194448+0.01789838j  0.02841914+0.04746556j\n",
      " -0.03256223-0.01424292j  0.01785527+0.02094028j -0.00651133-0.05367784j\n",
      " -0.00317138+0.0419485j ]\n"
     ]
    }
   ],
   "source": [
    "# --- loop - draw a single sample and plot ---\n",
    "\n",
    "dataset = BasicDatasetLT(model.hparams.data_path, train=False)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=0, shuffle=True)\n",
    "\n",
    "# loader = DataLoader(model.dataset_train, batch_size=1, num_workers=0, shuffle=True)\n",
    "for x,y in loader:\n",
    "\n",
    "    y_hat = model(x)\n",
    "\n",
    "    x = complextorch2numpy(x[0])\n",
    "    y = complextorch2numpy(y[0])\n",
    "    y_hat = complextorch2numpy(y_hat[0])\n",
    "\n",
    "    vis.compare_covs(x, y_hat, y)\n",
    "    vis.compare_power_maps(x, y_hat, y)\n",
    "    \n",
    "    print(x[0])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
